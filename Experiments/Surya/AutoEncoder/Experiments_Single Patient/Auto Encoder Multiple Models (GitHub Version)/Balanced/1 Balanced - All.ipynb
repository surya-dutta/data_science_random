{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5457a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a notebook to summarize all different models.\n",
    "# THis notebook was not run\n",
    "\n",
    "\n",
    "## Balanced AutoEncoder\n",
    "# encoder_dense_layers_trial = [[10, 8], [12, 10], [14, 12], [16, 14], [18, 16], [20, 18] ,[22,20]]\n",
    "# decoder_dense_layers_trial = [[8, 10], [10, 12], [12, 14], [14, 16], [16, 18], [18, 20], [20,22]]\n",
    "# bottle_neck_trial = [8, 10, 12, 14, 16, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd1301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable Warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a848f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE1 = 'SB-001_normalized_AM.csv'\n",
    "FILE2 = 'SB-001_normalized_PM.csv'\n",
    "NO_OF_COLUMNS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582f1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tf2onnx\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import cv2\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings('ignore', message=r'.*Consider either turning off auto-sharding.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501994a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b84dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autoencoder_reports(encoder_dense_layers, bottle_neck, decoder_dense_layers):\n",
    "\n",
    "    print(encoder_dense_layers, bottle_neck, decoder_dense_layers)\n",
    "    # Load Data\n",
    "    df_am = pd.read_csv(FILE1)\n",
    "    df_pm = pd.read_csv(FILE2)\n",
    "    combined_df = pd.concat([df_am, df_pm])\n",
    "\n",
    "    columns_needed = ['y_am_pef', 'tempin', 'humidin', 'pm25in', 'co2in', 'tempdiffin', 'humidiffin', 'pm25diffin',\n",
    "                      'pm10', 'pm25', 'o3', 'no2', 'co', 'so2', 'temp', 'windsd', 'humid', 'varp', 'dewpt', 'airp',\n",
    "                      'seap', 'solrhr', 'solramnt', 'grdt', 'class']\n",
    "    combined_df = combined_df.filter(columns_needed)\n",
    "    df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Drop NaN\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Minotity Split\n",
    "    class_counts = df['class'].value_counts()\n",
    "    minority_class = df[df['class'] == 0]\n",
    "    majority_class = df[df['class'] == 1]\n",
    "\n",
    "    # Removing class column from minority before augmentation\n",
    "    X = minority_class.drop('class', axis=1)\n",
    "    y = minority_class['class']\n",
    "\n",
    "    # Saving minority as X_train\n",
    "    X_train = X\n",
    "\n",
    "    # Define the Input shape\n",
    "    INPUT_SHAPE = X_train.shape[1]\n",
    "    FILE_NAME = f\"L{INPUT_SHAPE}_E{'_'.join(map(str, encoder_dense_layers))}_B{bottle_neck}_D{'_'.join(map(str, decoder_dense_layers))}\"\n",
    "    print(\"\\n\" + FILE_NAME + \"\\n\")\n",
    "    \n",
    "    def build_autoencoder(input_shape, **kwargs):\n",
    "\n",
    "        # Autoencoder model construction cod\n",
    "\n",
    "      \"\"\"\n",
    "      Build an autoencoder model with the given configuration.\n",
    "\n",
    "      Args:\n",
    "          input_shape (int): The shape of the input data.\n",
    "          **kwargs: Additional keyword arguments for configuring the autoencoder.\n",
    "\n",
    "      Keyword Args:\n",
    "          encoder_dense_layers (list): List of integers specifying the number of units for each dense layer in the encoder.\n",
    "                                      Default: []\n",
    "          bottle_neck (int): The number of units in the bottleneck layer. Default: input_shape // 2\n",
    "          decoder_dense_layers (list): List of integers specifying the number of units for each dense layer in the decoder.\n",
    "                                      Default: []\n",
    "          decoder_activation (str): The activation function for the decoder output layer. Default: 'sigmoid'\n",
    "\n",
    "      Returns:\n",
    "          tuple: A tuple containing the autoencoder, encoder, and decoder models.\n",
    "\n",
    "      Example:\n",
    "          INPUT_SHAPE = 27\n",
    "          encoder_dense_layers = [20, 18]  # Specify the number of units for each dense layer in the encoder\n",
    "          bottle_neck = 16\n",
    "          decoder_dense_layers = [18, 20]  # Specify the number of units for each dense layer in the decoder\n",
    "\n",
    "          autoencoder, encoder, decoder = build_autoencoder(INPUT_SHAPE, encoder_dense_layers=encoder_dense_layers,\n",
    "                                                            bottle_neck=bottle_neck, decoder_dense_layers=decoder_dense_layers)\n",
    "          encoder.summary()\n",
    "          decoder.summary()\n",
    "          autoencoder.summary()\n",
    "      \"\"\"\n",
    "\n",
    "      # Default parameter values\n",
    "      encoder_dense_layers = kwargs.get('encoder_dense_layers', [])\n",
    "      bottle_neck = kwargs.get('bottle_neck', input_shape // 2)\n",
    "      decoder_dense_layers = kwargs.get('decoder_dense_layers', [])\n",
    "      decoder_activation = kwargs.get('decoder_activation', 'sigmoid')\n",
    "\n",
    "      # Autoencoder Model\n",
    "      encoder_input = keras.Input(shape=(input_shape,), name=\"encoder\")\n",
    "      x = keras.layers.Flatten()(encoder_input)\n",
    "\n",
    "      # Encoder Dense Layers\n",
    "      for units in encoder_dense_layers:\n",
    "          x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
    "\n",
    "      encoder_output = keras.layers.Dense(bottle_neck, activation=\"relu\")(x)\n",
    "      encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "      # Decoder Model\n",
    "      decoder_input = keras.Input(shape=(bottle_neck,), name=\"decoder\")\n",
    "      x = decoder_input\n",
    "\n",
    "      # Decoder Dense Layers\n",
    "      for units in decoder_dense_layers:\n",
    "          x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
    "\n",
    "      decoder_output = keras.layers.Dense(input_shape, activation=decoder_activation)(x)\n",
    "      decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "      # Autoencoder Model\n",
    "      autoencoder_input = keras.Input(shape=(input_shape,), name=\"input\")\n",
    "      encoded = encoder(autoencoder_input)\n",
    "      decoded = decoder(encoded)\n",
    "      autoencoder = keras.Model(autoencoder_input, decoded, name=\"autoencoder\")\n",
    "\n",
    "      return autoencoder, encoder, decoder\n",
    "\n",
    "    autoencoder, encoder, decoder = build_autoencoder(INPUT_SHAPE, encoder_dense_layers=encoder_dense_layers,\n",
    "                                                      bottle_neck=bottle_neck,\n",
    "                                                      decoder_dense_layers=decoder_dense_layers)\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    autoencoder.compile(opt, loss=\"mse\")\n",
    "\n",
    "    print(\"Training model:\", FILE_NAME)\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=200, batch_size=16, validation_split=0.25, verbose=0)\n",
    "    print(\"Training Complete:\")\n",
    "    \n",
    "    # Extract the loss values\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Print the last epoch's loss values\n",
    "    last_epoch_loss = loss[-1]\n",
    "    last_epoch_val_loss = val_loss[-1]\n",
    "    print(\"Last epoch loss:\", last_epoch_loss)\n",
    "    print(\"Last epoch validation loss:\", last_epoch_val_loss)\n",
    "\n",
    "    # Saving history\n",
    "    with open(FILE_NAME + '_history.pickle', 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "    # Visualize losses *(MSE)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(FILE_NAME + 'Loss.png')\n",
    "    #plt.show()\n",
    "\n",
    "    # Generate synthetic data\n",
    "    num_samples = len(X_train)\n",
    "    input_data = np.random.normal(size=(num_samples, INPUT_SHAPE))\n",
    "    generated_data = autoencoder.predict(input_data)\n",
    "    reshaped_data = generated_data.reshape(num_samples, -1)\n",
    "    df_generated = pd.DataFrame(reshaped_data, columns=X_train.columns)\n",
    "\n",
    "    # Plot correlation matrices\n",
    "    corr_matrix1 = X_train.corr()\n",
    "    corr_matrix2 = df_generated.corr()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "    sns.heatmap(corr_matrix1, annot=True, cmap='coolwarm', ax=axes[0])\n",
    "    axes[0].set_title('Heatmap 1')\n",
    "\n",
    "    sns.heatmap(corr_matrix2, annot=True, cmap='coolwarm', ax=axes[1])\n",
    "    axes[1].set_title('Heatmap 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FILE_NAME + 'HeatMaps')\n",
    "    #plt.show()\n",
    "\n",
    "    # Calculate mean and standard deviation of original and synthetic datasets\n",
    "    common_columns = set(X_train.columns) & set(df_generated.columns)\n",
    "    results = {}\n",
    "\n",
    "    for column in common_columns:\n",
    "        mean_df1 = X_train[column].mean()\n",
    "        std_df1 = X_train[column].std()\n",
    "        mean_df2 = df_generated[column].mean()\n",
    "        std_df2 = df_generated[column].std()\n",
    "\n",
    "        results[column] = {'Mean_df1': mean_df1, 'Std_df1': std_df1,\n",
    "                           'Mean_df2': mean_df2, 'Std_df2': std_df2}\n",
    "\n",
    "    comparison_df = pd.DataFrame(results)\n",
    "    comparison_df.to_csv(FILE_NAME + 'mean_std.csv', index=True)\n",
    "\n",
    "    # Plot scatter plots\n",
    "    new_index = pd.RangeIndex(start=0, stop=57, step=1)\n",
    "    X_train = X_train.set_index(new_index)\n",
    "    common_columns = set(X_train.columns) & set(df_generated.columns)\n",
    "\n",
    "    for column in common_columns:\n",
    "        plt.scatter(X_train.index, X_train[column], color='red', label='X_train')\n",
    "        plt.scatter(df_generated.index, df_generated[column], color='blue', label='df_generated')\n",
    "\n",
    "        plt.title(f\"Scatter Plot: {column}\")\n",
    "        plt.xlabel(\"Index\")\n",
    "        plt.ylabel(column)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.savefig(FILE_NAME + \"_\" + column)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    # Add back the class label\n",
    "    X_train['class'] = 0.0\n",
    "    df_generated['class'] = 0.0\n",
    "    X_train.to_csv(FILE_NAME + 'Original_minority_data.csv', index=False)\n",
    "    df_generated.to_csv(FILE_NAME + 'Synthetic_minority_data.csv', index=False)\n",
    "\n",
    "    # Generate quality report and display it\n",
    "    real_data = FILE_NAME + 'Original_minority_data.csv'\n",
    "    synth_data = FILE_NAME + 'Synthetic_minority_data.csv'\n",
    "\n",
    "    # report = QualityReport(data_source=synth_data, ref_data=real_data)\n",
    "    # report.run()\n",
    "\n",
    "    # print(report.peek())\n",
    "    #run_summary.append([FILE_NAME, report.peek()['raw_score'], report.peek()['grade']])\n",
    "    run_summary.append([FILE_NAME, last_epoch_loss, last_epoch_val_loss])\n",
    "\n",
    "    print(\"Reports Saved\")\n",
    "    #IPython.display.HTML(report.as_html, metadata=dict(isolated=True))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddba8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def runner(encoder_dense_layers, bottle_neck, decoder_dense_layers):\n",
    "  #encoder_dense_layers = [10, 8]\n",
    "  #bottle_neck = 5\n",
    "  #decoder_dense_layers = [8, 10]\n",
    "  #FILE_NAME = f\"24_{'_'.join(map(str, encoder_dense_layers))}_{bottle_neck}_\"\n",
    "  FILE_NAME = f\"L{NO_OF_COLUMNS}_E{'_'.join(map(str, encoder_dense_layers))}_B{bottle_neck}_D{'_'.join(map(str, decoder_dense_layers))}\"   \n",
    "  report = generate_autoencoder_reports(encoder_dense_layers, bottle_neck, decoder_dense_layers)\n",
    "  #print(type(report))\n",
    "  # Save the report object to a file\n",
    "  # with open(FILE_NAME + 'quality_report.pickle', 'wb') as file:\n",
    "  #     pickle.dump(report, file)\n",
    "\n",
    "  #IPython.display.HTML(report.as_html, metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26fdef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes nothin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209f5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dense_layers_trial = [[10, 8], [12, 10], [14, 12], [16, 14], [18, 16], [20, 18] ,[22,20]]\n",
    "decoder_dense_layers_trial = [[8, 10], [10, 12], [12, 14], [14, 16], [16, 18], [18, 20], [20,22]]\n",
    "bottle_neck_trial = [8, 10, 12, 14, 16, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f3da03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model in Pipeline: 294\n",
      "[10, 8] 8 [8, 10]\n",
      "[10, 8] 8 [10, 12]\n",
      "[10, 8] 8 [12, 14]\n",
      "[10, 8] 8 [14, 16]\n",
      "[10, 8] 8 [16, 18]\n",
      "[10, 8] 8 [18, 20]\n",
      "[10, 8] 8 [20, 22]\n",
      "[12, 10] 8 [8, 10]\n",
      "[12, 10] 8 [10, 12]\n",
      "[12, 10] 8 [12, 14]\n",
      "[12, 10] 8 [14, 16]\n",
      "[12, 10] 8 [16, 18]\n",
      "[12, 10] 8 [18, 20]\n",
      "[12, 10] 8 [20, 22]\n",
      "[14, 12] 8 [8, 10]\n",
      "[14, 12] 8 [10, 12]\n",
      "[14, 12] 8 [12, 14]\n",
      "[14, 12] 8 [14, 16]\n",
      "[14, 12] 8 [16, 18]\n",
      "[14, 12] 8 [18, 20]\n",
      "[14, 12] 8 [20, 22]\n",
      "[16, 14] 8 [8, 10]\n",
      "[16, 14] 8 [10, 12]\n",
      "[16, 14] 8 [12, 14]\n",
      "[16, 14] 8 [14, 16]\n",
      "[16, 14] 8 [16, 18]\n",
      "[16, 14] 8 [18, 20]\n",
      "[16, 14] 8 [20, 22]\n",
      "[18, 16] 8 [8, 10]\n",
      "[18, 16] 8 [10, 12]\n",
      "[18, 16] 8 [12, 14]\n",
      "[18, 16] 8 [14, 16]\n",
      "[18, 16] 8 [16, 18]\n",
      "[18, 16] 8 [18, 20]\n",
      "[18, 16] 8 [20, 22]\n",
      "[20, 18] 8 [8, 10]\n",
      "[20, 18] 8 [10, 12]\n",
      "[20, 18] 8 [12, 14]\n",
      "[20, 18] 8 [14, 16]\n",
      "[20, 18] 8 [16, 18]\n",
      "[20, 18] 8 [18, 20]\n",
      "[20, 18] 8 [20, 22]\n",
      "[22, 20] 8 [8, 10]\n",
      "[22, 20] 8 [10, 12]\n",
      "[22, 20] 8 [12, 14]\n",
      "[22, 20] 8 [14, 16]\n",
      "[22, 20] 8 [16, 18]\n",
      "[22, 20] 8 [18, 20]\n",
      "[22, 20] 8 [20, 22]\n",
      "[10, 8] 10 [8, 10]\n",
      "[10, 8] 10 [10, 12]\n",
      "[10, 8] 10 [12, 14]\n",
      "[10, 8] 10 [14, 16]\n",
      "[10, 8] 10 [16, 18]\n",
      "[10, 8] 10 [18, 20]\n",
      "[10, 8] 10 [20, 22]\n",
      "[12, 10] 10 [8, 10]\n",
      "[12, 10] 10 [10, 12]\n",
      "[12, 10] 10 [12, 14]\n",
      "[12, 10] 10 [14, 16]\n",
      "[12, 10] 10 [16, 18]\n",
      "[12, 10] 10 [18, 20]\n",
      "[12, 10] 10 [20, 22]\n",
      "[14, 12] 10 [8, 10]\n",
      "[14, 12] 10 [10, 12]\n",
      "[14, 12] 10 [12, 14]\n",
      "[14, 12] 10 [14, 16]\n",
      "[14, 12] 10 [16, 18]\n",
      "[14, 12] 10 [18, 20]\n",
      "[14, 12] 10 [20, 22]\n",
      "[16, 14] 10 [8, 10]\n",
      "[16, 14] 10 [10, 12]\n",
      "[16, 14] 10 [12, 14]\n",
      "[16, 14] 10 [14, 16]\n",
      "[16, 14] 10 [16, 18]\n",
      "[16, 14] 10 [18, 20]\n",
      "[16, 14] 10 [20, 22]\n",
      "[18, 16] 10 [8, 10]\n",
      "[18, 16] 10 [10, 12]\n",
      "[18, 16] 10 [12, 14]\n",
      "[18, 16] 10 [14, 16]\n",
      "[18, 16] 10 [16, 18]\n",
      "[18, 16] 10 [18, 20]\n",
      "[18, 16] 10 [20, 22]\n",
      "[20, 18] 10 [8, 10]\n",
      "[20, 18] 10 [10, 12]\n",
      "[20, 18] 10 [12, 14]\n",
      "[20, 18] 10 [14, 16]\n",
      "[20, 18] 10 [16, 18]\n",
      "[20, 18] 10 [18, 20]\n",
      "[20, 18] 10 [20, 22]\n",
      "[22, 20] 10 [8, 10]\n",
      "[22, 20] 10 [10, 12]\n",
      "[22, 20] 10 [12, 14]\n",
      "[22, 20] 10 [14, 16]\n",
      "[22, 20] 10 [16, 18]\n",
      "[22, 20] 10 [18, 20]\n",
      "[22, 20] 10 [20, 22]\n",
      "[10, 8] 12 [8, 10]\n",
      "[10, 8] 12 [10, 12]\n",
      "[10, 8] 12 [12, 14]\n",
      "[10, 8] 12 [14, 16]\n",
      "[10, 8] 12 [16, 18]\n",
      "[10, 8] 12 [18, 20]\n",
      "[10, 8] 12 [20, 22]\n",
      "[12, 10] 12 [8, 10]\n",
      "[12, 10] 12 [10, 12]\n",
      "[12, 10] 12 [12, 14]\n",
      "[12, 10] 12 [14, 16]\n",
      "[12, 10] 12 [16, 18]\n",
      "[12, 10] 12 [18, 20]\n",
      "[12, 10] 12 [20, 22]\n",
      "[14, 12] 12 [8, 10]\n",
      "[14, 12] 12 [10, 12]\n",
      "[14, 12] 12 [12, 14]\n",
      "[14, 12] 12 [14, 16]\n",
      "[14, 12] 12 [16, 18]\n",
      "[14, 12] 12 [18, 20]\n",
      "[14, 12] 12 [20, 22]\n",
      "[16, 14] 12 [8, 10]\n",
      "[16, 14] 12 [10, 12]\n",
      "[16, 14] 12 [12, 14]\n",
      "[16, 14] 12 [14, 16]\n",
      "[16, 14] 12 [16, 18]\n",
      "[16, 14] 12 [18, 20]\n",
      "[16, 14] 12 [20, 22]\n",
      "[18, 16] 12 [8, 10]\n",
      "[18, 16] 12 [10, 12]\n",
      "[18, 16] 12 [12, 14]\n",
      "[18, 16] 12 [14, 16]\n",
      "[18, 16] 12 [16, 18]\n",
      "[18, 16] 12 [18, 20]\n",
      "[18, 16] 12 [20, 22]\n",
      "[20, 18] 12 [8, 10]\n",
      "[20, 18] 12 [10, 12]\n",
      "[20, 18] 12 [12, 14]\n",
      "[20, 18] 12 [14, 16]\n",
      "[20, 18] 12 [16, 18]\n",
      "[20, 18] 12 [18, 20]\n",
      "[20, 18] 12 [20, 22]\n",
      "[22, 20] 12 [8, 10]\n",
      "[22, 20] 12 [10, 12]\n",
      "[22, 20] 12 [12, 14]\n",
      "[22, 20] 12 [14, 16]\n",
      "[22, 20] 12 [16, 18]\n",
      "[22, 20] 12 [18, 20]\n",
      "[22, 20] 12 [20, 22]\n",
      "[10, 8] 14 [8, 10]\n",
      "[10, 8] 14 [10, 12]\n",
      "[10, 8] 14 [12, 14]\n",
      "[10, 8] 14 [14, 16]\n",
      "[10, 8] 14 [16, 18]\n",
      "[10, 8] 14 [18, 20]\n",
      "[10, 8] 14 [20, 22]\n",
      "[12, 10] 14 [8, 10]\n",
      "[12, 10] 14 [10, 12]\n",
      "[12, 10] 14 [12, 14]\n",
      "[12, 10] 14 [14, 16]\n",
      "[12, 10] 14 [16, 18]\n",
      "[12, 10] 14 [18, 20]\n",
      "[12, 10] 14 [20, 22]\n",
      "[14, 12] 14 [8, 10]\n",
      "[14, 12] 14 [10, 12]\n",
      "[14, 12] 14 [12, 14]\n",
      "[14, 12] 14 [14, 16]\n",
      "[14, 12] 14 [16, 18]\n",
      "[14, 12] 14 [18, 20]\n",
      "[14, 12] 14 [20, 22]\n",
      "[16, 14] 14 [8, 10]\n",
      "[16, 14] 14 [10, 12]\n",
      "[16, 14] 14 [12, 14]\n",
      "[16, 14] 14 [14, 16]\n",
      "[16, 14] 14 [16, 18]\n",
      "[16, 14] 14 [18, 20]\n",
      "[16, 14] 14 [20, 22]\n",
      "[18, 16] 14 [8, 10]\n",
      "[18, 16] 14 [10, 12]\n",
      "[18, 16] 14 [12, 14]\n",
      "[18, 16] 14 [14, 16]\n",
      "[18, 16] 14 [16, 18]\n",
      "[18, 16] 14 [18, 20]\n",
      "[18, 16] 14 [20, 22]\n",
      "[20, 18] 14 [8, 10]\n",
      "[20, 18] 14 [10, 12]\n",
      "[20, 18] 14 [12, 14]\n",
      "[20, 18] 14 [14, 16]\n",
      "[20, 18] 14 [16, 18]\n",
      "[20, 18] 14 [18, 20]\n",
      "[20, 18] 14 [20, 22]\n",
      "[22, 20] 14 [8, 10]\n",
      "[22, 20] 14 [10, 12]\n",
      "[22, 20] 14 [12, 14]\n",
      "[22, 20] 14 [14, 16]\n",
      "[22, 20] 14 [16, 18]\n",
      "[22, 20] 14 [18, 20]\n",
      "[22, 20] 14 [20, 22]\n",
      "[10, 8] 16 [8, 10]\n",
      "[10, 8] 16 [10, 12]\n",
      "[10, 8] 16 [12, 14]\n",
      "[10, 8] 16 [14, 16]\n",
      "[10, 8] 16 [16, 18]\n",
      "[10, 8] 16 [18, 20]\n",
      "[10, 8] 16 [20, 22]\n",
      "[12, 10] 16 [8, 10]\n",
      "[12, 10] 16 [10, 12]\n",
      "[12, 10] 16 [12, 14]\n",
      "[12, 10] 16 [14, 16]\n",
      "[12, 10] 16 [16, 18]\n",
      "[12, 10] 16 [18, 20]\n",
      "[12, 10] 16 [20, 22]\n",
      "[14, 12] 16 [8, 10]\n",
      "[14, 12] 16 [10, 12]\n",
      "[14, 12] 16 [12, 14]\n",
      "[14, 12] 16 [14, 16]\n",
      "[14, 12] 16 [16, 18]\n",
      "[14, 12] 16 [18, 20]\n",
      "[14, 12] 16 [20, 22]\n",
      "[16, 14] 16 [8, 10]\n",
      "[16, 14] 16 [10, 12]\n",
      "[16, 14] 16 [12, 14]\n",
      "[16, 14] 16 [14, 16]\n",
      "[16, 14] 16 [16, 18]\n",
      "[16, 14] 16 [18, 20]\n",
      "[16, 14] 16 [20, 22]\n",
      "[18, 16] 16 [8, 10]\n",
      "[18, 16] 16 [10, 12]\n",
      "[18, 16] 16 [12, 14]\n",
      "[18, 16] 16 [14, 16]\n",
      "[18, 16] 16 [16, 18]\n",
      "[18, 16] 16 [18, 20]\n",
      "[18, 16] 16 [20, 22]\n",
      "[20, 18] 16 [8, 10]\n",
      "[20, 18] 16 [10, 12]\n",
      "[20, 18] 16 [12, 14]\n",
      "[20, 18] 16 [14, 16]\n",
      "[20, 18] 16 [16, 18]\n",
      "[20, 18] 16 [18, 20]\n",
      "[20, 18] 16 [20, 22]\n",
      "[22, 20] 16 [8, 10]\n",
      "[22, 20] 16 [10, 12]\n",
      "[22, 20] 16 [12, 14]\n",
      "[22, 20] 16 [14, 16]\n",
      "[22, 20] 16 [16, 18]\n",
      "[22, 20] 16 [18, 20]\n",
      "[22, 20] 16 [20, 22]\n",
      "[10, 8] 18 [8, 10]\n",
      "[10, 8] 18 [10, 12]\n",
      "[10, 8] 18 [12, 14]\n",
      "[10, 8] 18 [14, 16]\n",
      "[10, 8] 18 [16, 18]\n",
      "[10, 8] 18 [18, 20]\n",
      "[10, 8] 18 [20, 22]\n",
      "[12, 10] 18 [8, 10]\n",
      "[12, 10] 18 [10, 12]\n",
      "[12, 10] 18 [12, 14]\n",
      "[12, 10] 18 [14, 16]\n",
      "[12, 10] 18 [16, 18]\n",
      "[12, 10] 18 [18, 20]\n",
      "[12, 10] 18 [20, 22]\n",
      "[14, 12] 18 [8, 10]\n",
      "[14, 12] 18 [10, 12]\n",
      "[14, 12] 18 [12, 14]\n",
      "[14, 12] 18 [14, 16]\n",
      "[14, 12] 18 [16, 18]\n",
      "[14, 12] 18 [18, 20]\n",
      "[14, 12] 18 [20, 22]\n",
      "[16, 14] 18 [8, 10]\n",
      "[16, 14] 18 [10, 12]\n",
      "[16, 14] 18 [12, 14]\n",
      "[16, 14] 18 [14, 16]\n",
      "[16, 14] 18 [16, 18]\n",
      "[16, 14] 18 [18, 20]\n",
      "[16, 14] 18 [20, 22]\n",
      "[18, 16] 18 [8, 10]\n",
      "[18, 16] 18 [10, 12]\n",
      "[18, 16] 18 [12, 14]\n",
      "[18, 16] 18 [14, 16]\n",
      "[18, 16] 18 [16, 18]\n",
      "[18, 16] 18 [18, 20]\n",
      "[18, 16] 18 [20, 22]\n",
      "[20, 18] 18 [8, 10]\n",
      "[20, 18] 18 [10, 12]\n",
      "[20, 18] 18 [12, 14]\n",
      "[20, 18] 18 [14, 16]\n",
      "[20, 18] 18 [16, 18]\n",
      "[20, 18] 18 [18, 20]\n",
      "[20, 18] 18 [20, 22]\n",
      "[22, 20] 18 [8, 10]\n",
      "[22, 20] 18 [10, 12]\n",
      "[22, 20] 18 [12, 14]\n",
      "[22, 20] 18 [14, 16]\n",
      "[22, 20] 18 [16, 18]\n",
      "[22, 20] 18 [18, 20]\n",
      "[22, 20] 18 [20, 22]\n"
     ]
    }
   ],
   "source": [
    "total_iterations = len(bottle_neck_trial) * len(encoder_dense_layers_trial) * len(decoder_dense_layers_trial)\n",
    "print(\"Total Model in Pipeline:\",total_iterations)\n",
    "\n",
    "# Print total models\n",
    "for bn in bottle_neck_trial:\n",
    "  for enc_layers in encoder_dense_layers_trial:\n",
    "      for dec_layers in decoder_dense_layers_trial:\n",
    "          print(enc_layers, bn, dec_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92caf46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Type\tBottleneck\tModel\tTraining Loss\tValidation Loss\n",
    "Balanced\tB8\tL24_E10_8_B8_D8_10\t0.014485765\t0.022974495\n",
    "Balanced\tB8\tL24_E10_8_B8_D10_12\t0.01060681\t0.017263062\n",
    "Balanced\tB8\tL24_E10_8_B8_D12_14\t0.011916933\t0.018185237\n",
    "Balanced\tB8\tL24_E10_8_B8_D14_16\t0.011970292\t0.019739432\n",
    "Balanced\tB8\tL24_E10_8_B8_D16_18\t0.019925587\t0.030561503\n",
    "Balanced\tB8\tL24_E10_8_B8_D18_20\t0.010648762\t0.017230611\n",
    "Balanced\tB8\tL24_E10_8_B8_D20_22\t0.008817361\t0.014682335\n",
    "Balanced\tB8\tL24_E12_10_B8_D8_10\t0.019411495\t0.029249368\n",
    "Balanced\tB8\tL24_E12_10_B8_D10_12\t0.01750912\t0.026244964\n",
    "Balanced\tB8\tL24_E12_10_B8_D12_14\t0.010249116\t0.016656721\n",
    "Balanced\tB8\tL24_E12_10_B8_D14_16\t0.013395854\t0.020195358\n",
    "Balanced\tB8\tL24_E12_10_B8_D16_18\t0.01126899\t0.019461954\n",
    "Balanced\tB8\tL24_E12_10_B8_D18_20\t0.008945597\t0.014437428\n",
    "Balanced\tB8\tL24_E12_10_B8_D20_22\t0.012319727\t0.018815922\n",
    "Balanced\tB8\tL24_E14_12_B8_D8_10\t0.012731771\t0.021036537\n",
    "Balanced\tB8\tL24_E14_12_B8_D10_12\t0.011132245\t0.017919274\n",
    "Balanced\tB8\tL24_E14_12_B8_D12_14\t0.013684283\t0.020270029\n",
    "Balanced\tB8\tL24_E14_12_B8_D14_16\t0.010775772\t0.017332792\n",
    "Balanced\tB8\tL24_E14_12_B8_D16_18\t0.011125657\t0.017446777\n",
    "Balanced\tB8\tL24_E14_12_B8_D18_20\t0.01094774\t0.01628216\n",
    "Balanced\tB8\tL24_E14_12_B8_D20_22\t0.007277598\t0.014432641\n",
    "Balanced\tB8\tL24_E16_14_B8_D8_10\t0.015016627\t0.022679856\n",
    "Balanced\tB8\tL24_E16_14_B8_D10_12\t0.013373789\t0.019602077\n",
    "Balanced\tB8\tL24_E16_14_B8_D12_14\t0.012410827\t0.019148977\n",
    "Balanced\tB8\tL24_E16_14_B8_D14_16\t0.011969252\t0.017746914\n",
    "Balanced\tB8\tL24_E16_14_B8_D16_18\t0.00820365\t0.013060251\n",
    "Balanced\tB8\tL24_E16_14_B8_D18_20\t0.007562756\t0.01258753\n",
    "Balanced\tB8\tL24_E16_14_B8_D20_22\t0.007976608\t0.013764562\n",
    "Balanced\tB8\tL24_E18_16_B8_D8_10\t0.019272298\t0.027413798\n",
    "Balanced\tB8\tL24_E18_16_B8_D10_12\t0.018363694\t0.027087046\n",
    "Balanced\tB8\tL24_E18_16_B8_D12_14\t0.011286693\t0.018138178\n",
    "Balanced\tB8\tL24_E18_16_B8_D14_16\t0.010196437\t0.016214075\n",
    "Balanced\tB8\tL24_E18_16_B8_D16_18\t0.009142173\t0.01462759\n",
    "Balanced\tB8\tL24_E18_16_B8_D18_20\t0.007723502\t0.0126371\n",
    "Balanced\tB8\tL24_E18_16_B8_D20_22\t0.016000131\t0.031696063\n",
    "Balanced\tB8\tL24_E20_18_B8_D8_10\t0.012469248\t0.018660728\n",
    "Balanced\tB8\tL24_E20_18_B8_D10_12\t0.011384247\t0.017297527\n",
    "Balanced\tB8\tL24_E20_18_B8_D12_14\t0.007756393\t0.01389248\n",
    "Balanced\tB8\tL24_E20_18_B8_D14_16\t0.010571545\t0.017923929\n",
    "Balanced\tB8\tL24_E20_18_B8_D16_18\t0.010552365\t0.018388778\n",
    "Balanced\tB8\tL24_E20_18_B8_D18_20\t0.011967959\t0.018513737\n",
    "Balanced\tB8\tL24_E20_18_B8_D20_22\t0.008885314\t0.014631391\n",
    "Balanced\tB8\tL24_E22_20_B8_D8_10\t0.015228407\t0.026589355\n",
    "Balanced\tB8\tL24_E22_20_B8_D10_12\t0.010015349\t0.016706284\n",
    "Balanced\tB8\tL24_E22_20_B8_D12_14\t0.010139124\t0.015177434\n",
    "Balanced\tB8\tL24_E22_20_B8_D14_16\t0.007095151\t0.011576039\n",
    "Balanced\tB8\tL24_E22_20_B8_D16_18\t0.0095194\t0.016322633\n",
    "Balanced\tB8\tL24_E22_20_B8_D18_20\t0.008468733\t0.014596486\n",
    "Balanced\tB8\tL24_E22_20_B8_D20_22\t0.00928088\t0.01695844\n",
    "Balanced\tB10\tL24_E10_8_B10_D8_10\t0.020233354\t0.030165875\n",
    "Balanced\tB10\tL24_E10_8_B10_D10_12\t0.011752107\t0.019158585\n",
    "Balanced\tB10\tL24_E10_8_B10_D12_14\t0.013033877\t0.021106085\n",
    "Balanced\tB10\tL24_E10_8_B10_D14_16\t0.009600295\t0.017440444\n",
    "Balanced\tB10\tL24_E10_8_B10_D16_18\t0.012266792\t0.019465182\n",
    "Balanced\tB10\tL24_E10_8_B10_D18_20\t0.012120275\t0.019972069\n",
    "Balanced\tB10\tL24_E10_8_B10_D20_22\t0.011167606\t0.018437615\n",
    "Balanced\tB10\tL24_E12_10_B10_D8_10\t0.016640469\t0.027864916\n",
    "Balanced\tB10\tL24_E12_10_B10_D10_12\t0.014428391\t0.021437526\n",
    "Balanced\tB10\tL24_E12_10_B10_D12_14\t0.011593088\t0.017778683\n",
    "Balanced\tB10\tL24_E12_10_B10_D14_16\t0.01202246\t0.018209089\n",
    "Balanced\tB10\tL24_E12_10_B10_D16_18\t0.011851581\t0.019077662\n",
    "Balanced\tB10\tL24_E12_10_B10_D18_20\t0.012331415\t0.018981433\n",
    "Balanced\tB10\tL24_E12_10_B10_D20_22\t0.013418073\t0.020311581\n",
    "Balanced\tB10\tL24_E14_12_B10_D8_10\t0.013110242\t0.018374674\n",
    "Balanced\tB10\tL24_E14_12_B10_D10_12\t0.011942232\t0.01844489\n",
    "Balanced\tB10\tL24_E14_12_B10_D12_14\t0.012435388\t0.019559812\n",
    "Balanced\tB10\tL24_E14_12_B10_D14_16\t0.011206926\t0.019238029\n",
    "Balanced\tB10\tL24_E14_12_B10_D16_18\t0.011803836\t0.018064195\n",
    "Balanced\tB10\tL24_E14_12_B10_D18_20\t0.007719166\t0.014410676\n",
    "Balanced\tB10\tL24_E14_12_B10_D20_22\t0.014435138\t0.023483554\n",
    "Balanced\tB10\tL24_E16_14_B10_D8_10\t0.011077491\t0.018000929\n",
    "Balanced\tB10\tL24_E16_14_B10_D10_12\t0.01378517\t0.023309732\n",
    "Balanced\tB10\tL24_E16_14_B10_D12_14\t0.010775991\t0.017542208\n",
    "Balanced\tB10\tL24_E16_14_B10_D14_16\t0.008424668\t0.014197184\n",
    "Balanced\tB10\tL24_E16_14_B10_D16_18\t0.00744313\t0.01423794\n",
    "Balanced\tB10\tL24_E16_14_B10_D18_20\t0.008934898\t0.015064557\n",
    "Balanced\tB10\tL24_E16_14_B10_D20_22\t0.007145206\t0.013409941\n",
    "Balanced\tB10\tL24_E18_16_B10_D8_10\t0.017306797\t0.02824511\n",
    "Balanced\tB10\tL24_E18_16_B10_D10_12\t0.010003665\t0.015330164\n",
    "Balanced\tB10\tL24_E18_16_B10_D12_14\t0.009937397\t0.016804602\n",
    "Balanced\tB10\tL24_E18_16_B10_D14_16\t0.012277911\t0.023712898\n",
    "Balanced\tB10\tL24_E18_16_B10_D16_18\t0.011523508\t0.018302547\n",
    "Balanced\tB10\tL24_E18_16_B10_D18_20\t0.012922266\t0.019010309\n",
    "Balanced\tB10\tL24_E18_16_B10_D20_22\t0.009757383\t0.016663309\n",
    "Balanced\tB10\tL24_E20_18_B10_D8_10\t0.010633713\t0.01707088\n",
    "Balanced\tB10\tL24_E20_18_B10_D10_12\t0.012084598\t0.019233264\n",
    "Balanced\tB10\tL24_E20_18_B10_D12_14\t0.012043674\t0.018626062\n",
    "Balanced\tB10\tL24_E20_18_B10_D14_16\t0.00720043\t0.013535816\n",
    "Balanced\tB10\tL24_E20_18_B10_D16_18\t0.008152522\t0.013586865\n",
    "Balanced\tB10\tL24_E20_18_B10_D18_20\t0.006461348\t0.012377882\n",
    "Balanced\tB10\tL24_E20_18_B10_D20_22\t0.007735878\t0.013843983\n",
    "Balanced\tB10\tL24_E22_20_B10_D8_10\t0.013361105\t0.020751674\n",
    "Balanced\tB10\tL24_E22_20_B10_D10_12\t0.008585029\t0.014543698\n",
    "Balanced\tB10\tL24_E22_20_B10_D12_14\t0.010446116\t0.017029785\n",
    "Balanced\tB10\tL24_E22_20_B10_D14_16\t0.008400316\t0.014614398\n",
    "Balanced\tB10\tL24_E22_20_B10_D16_18\t0.006910736\t0.013537439\n",
    "Balanced\tB10\tL24_E22_20_B10_D18_20\t0.008596794\t0.014720659\n",
    "Balanced\tB10\tL24_E22_20_B10_D20_22\t0.008952353\t0.015115184\n",
    "Balanced\tB12\tL24_E10_8_B12_D8_10\t0.01414791\t0.021388927\n",
    "Balanced\tB12\tL24_E10_8_B12_D10_12\t0.015127592\t0.021743722\n",
    "Balanced\tB12\tL24_E10_8_B12_D12_14\t0.016536463\t0.024836285\n",
    "Balanced\tB12\tL24_E10_8_B12_D14_16\t0.012195566\t0.018959139\n",
    "Balanced\tB12\tL24_E10_8_B12_D16_18\t0.009245764\t0.016140325\n",
    "Balanced\tB12\tL24_E10_8_B12_D18_20\t0.016895046\t0.027062286\n",
    "Balanced\tB12\tL24_E10_8_B12_D20_22\t0.01102158\t0.018165346\n",
    "Balanced\tB12\tL24_E12_10_B12_D8_10\t0.01323293\t0.022367517\n",
    "Balanced\tB12\tL24_E12_10_B12_D10_12\t0.012452502\t0.019168895\n",
    "Balanced\tB12\tL24_E12_10_B12_D12_14\t0.009999213\t0.017334832\n",
    "Balanced\tB12\tL24_E12_10_B12_D14_16\t0.012689082\t0.02202631\n",
    "Balanced\tB12\tL24_E12_10_B12_D16_18\t0.010835116\t0.018292062\n",
    "Balanced\tB12\tL24_E12_10_B12_D18_20\t0.008599921\t0.015628215\n",
    "Balanced\tB12\tL24_E12_10_B12_D20_22\t0.014492693\t0.02245375\n",
    "Balanced\tB12\tL24_E14_12_B12_D8_10\t0.012676724\t0.01916324\n",
    "Balanced\tB12\tL24_E14_12_B12_D10_12\t0.008732004\t0.013772049\n",
    "Balanced\tB12\tL24_E14_12_B12_D12_14\t0.011853893\t0.018004227\n",
    "Balanced\tB12\tL24_E14_12_B12_D14_16\t0.011522301\t0.019759638\n",
    "Balanced\tB12\tL24_E14_12_B12_D16_18\t0.008111686\t0.012680038\n",
    "Balanced\tB12\tL24_E14_12_B12_D18_20\t0.008010929\t0.013925698\n",
    "Balanced\tB12\tL24_E14_12_B12_D20_22\t0.009043431\t0.015265347\n",
    "Balanced\tB12\tL24_E16_14_B12_D8_10\t0.018814253\t0.028026126\n",
    "Balanced\tB12\tL24_E16_14_B12_D10_12\t0.011674452\t0.019679721\n",
    "Balanced\tB12\tL24_E16_14_B12_D12_14\t0.0144563\t0.020627506\n",
    "Balanced\tB12\tL24_E16_14_B12_D14_16\t0.008486791\t0.014203359\n",
    "Balanced\tB12\tL24_E16_14_B12_D16_18\t0.008114704\t0.014175036\n",
    "Balanced\tB12\tL24_E16_14_B12_D18_20\t0.009361364\t0.016431458\n",
    "Balanced\tB12\tL24_E16_14_B12_D20_22\t0.006976177\t0.013434468\n",
    "Balanced\tB12\tL24_E18_16_B12_D8_10\t0.011200269\t0.01734951\n",
    "Balanced\tB12\tL24_E18_16_B12_D10_12\t0.008983563\t0.012933123\n",
    "Balanced\tB12\tL24_E18_16_B12_D12_14\t0.007961662\t0.013359638\n",
    "Balanced\tB12\tL24_E18_16_B12_D14_16\t0.008289513\t0.013923645\n",
    "Balanced\tB12\tL24_E18_16_B12_D16_18\t0.010341416\t0.018295681\n",
    "Balanced\tB12\tL24_E18_16_B12_D18_20\t0.010380821\t0.018231886\n",
    "Balanced\tB12\tL24_E18_16_B12_D20_22\t0.007641385\t0.013961554\n",
    "Balanced\tB12\tL24_E20_18_B12_D8_10\t0.013198731\t0.022337751\n",
    "Balanced\tB12\tL24_E20_18_B12_D10_12\t0.008621255\t0.01430322\n",
    "Balanced\tB12\tL24_E20_18_B12_D12_14\t0.007713827\t0.013112054\n",
    "Balanced\tB12\tL24_E20_18_B12_D14_16\t0.011884554\t0.018406086\n",
    "Balanced\tB12\tL24_E20_18_B12_D16_18\t0.008235321\t0.014060645\n",
    "Balanced\tB12\tL24_E20_18_B12_D18_20\t0.010465188\t0.017476635\n",
    "Balanced\tB12\tL24_E20_18_B12_D20_22\t0.006310659\t0.013337531\n",
    "Balanced\tB12\tL24_E22_20_B12_D8_10\t0.012796138\t0.020780822\n",
    "Balanced\tB12\tL24_E22_20_B12_D10_12\t0.010534339\t0.016327217\n",
    "Balanced\tB12\tL24_E22_20_B12_D12_14\t0.008848218\t0.013751759\n",
    "Balanced\tB12\tL24_E22_20_B12_D14_16\t0.008191936\t0.014229388\n",
    "Balanced\tB12\tL24_E22_20_B12_D16_18\t0.006092409\t0.01129731\n",
    "Balanced\tB12\tL24_E22_20_B12_D18_20\t0.009358768\t0.015475836\n",
    "Balanced\tB12\tL24_E22_20_B12_D20_22\t0.005709786\t0.011208725\n",
    "Balanced\tB14\tL24_E10_8_B14_D8_10\t0.016634461\t0.025318654\n",
    "Balanced\tB14\tL24_E10_8_B14_D10_12\t0.012433126\t0.020200988\n",
    "Balanced\tB14\tL24_E10_8_B14_D12_14\t0.011332768\t0.018543165\n",
    "Balanced\tB14\tL24_E10_8_B14_D14_16\t0.008746\t0.015377605\n",
    "Balanced\tB14\tL24_E10_8_B14_D16_18\t0.010634057\t0.018462891\n",
    "Balanced\tB14\tL24_E10_8_B14_D18_20\t0.00952878\t0.014417068\n",
    "Balanced\tB14\tL24_E10_8_B14_D20_22\t0.011492095\t0.020474436\n",
    "Balanced\tB14\tL24_E12_10_B14_D8_10\t0.014938395\t0.024738461\n",
    "Balanced\tB14\tL24_E12_10_B14_D10_12\t0.012164013\t0.017890533\n",
    "Balanced\tB14\tL24_E12_10_B14_D12_14\t0.011970019\t0.017954476\n",
    "Balanced\tB14\tL24_E12_10_B14_D14_16\t0.009808813\t0.017162852\n",
    "Balanced\tB14\tL24_E12_10_B14_D16_18\t0.010080094\t0.016826998\n",
    "Balanced\tB14\tL24_E12_10_B14_D18_20\t0.007452289\t0.014155453\n",
    "Balanced\tB14\tL24_E12_10_B14_D20_22\t0.012036892\t0.017635632\n",
    "Balanced\tB14\tL24_E14_12_B14_D8_10\t0.01119254\t0.017975081\n",
    "Balanced\tB14\tL24_E14_12_B14_D10_12\t0.011954973\t0.018746814\n",
    "Balanced\tB14\tL24_E14_12_B14_D12_14\t0.010655029\t0.017101269\n",
    "Balanced\tB14\tL24_E14_12_B14_D14_16\t0.009596703\t0.017062962\n",
    "Balanced\tB14\tL24_E14_12_B14_D16_18\t0.016678691\t0.02641063\n",
    "Balanced\tB14\tL24_E14_12_B14_D18_20\t0.006756256\t0.011424747\n",
    "Balanced\tB14\tL24_E14_12_B14_D20_22\t0.010530442\t0.018963279\n",
    "Balanced\tB14\tL24_E16_14_B14_D8_10\t0.01080025\t0.016407503\n",
    "Balanced\tB14\tL24_E16_14_B14_D10_12\t0.009111326\t0.014399161\n",
    "Balanced\tB14\tL24_E16_14_B14_D12_14\t0.012275641\t0.019249337\n",
    "Balanced\tB14\tL24_E16_14_B14_D14_16\t0.009489594\t0.016485734\n",
    "Balanced\tB14\tL24_E16_14_B14_D16_18\t0.010920933\t0.017181747\n",
    "Balanced\tB14\tL24_E16_14_B14_D18_20\t0.010095621\t0.019125881\n",
    "Balanced\tB14\tL24_E16_14_B14_D20_22\t0.006382407\t0.013860118\n",
    "Balanced\tB14\tL24_E18_16_B14_D8_10\t0.012584542\t0.019625643\n",
    "Balanced\tB14\tL24_E18_16_B14_D10_12\t0.011038356\t0.017034989\n",
    "Balanced\tB14\tL24_E18_16_B14_D12_14\t0.012321697\t0.020131405\n",
    "Balanced\tB14\tL24_E18_16_B14_D14_16\t0.010447945\t0.018016152\n",
    "Balanced\tB14\tL24_E18_16_B14_D16_18\t0.011566822\t0.01698165\n",
    "Balanced\tB14\tL24_E18_16_B14_D18_20\t0.008635782\t0.015291593\n",
    "Balanced\tB14\tL24_E18_16_B14_D20_22\t0.006776017\t0.015732039\n",
    "Balanced\tB14\tL24_E20_18_B14_D8_10\t0.011501783\t0.018860975\n",
    "Balanced\tB14\tL24_E20_18_B14_D10_12\t0.010963756\t0.017627282\n",
    "Balanced\tB14\tL24_E20_18_B14_D12_14\t0.008121886\t0.012793698\n",
    "Balanced\tB14\tL24_E20_18_B14_D14_16\t0.01155027\t0.01921783\n",
    "Balanced\tB14\tL24_E20_18_B14_D16_18\t0.007514947\t0.014350478\n",
    "Balanced\tB14\tL24_E20_18_B14_D18_20\t0.007838466\t0.012812638\n",
    "Balanced\tB14\tL24_E20_18_B14_D20_22\t0.005615217\t0.011539103\n",
    "Balanced\tB14\tL24_E22_20_B14_D8_10\t0.012641335\t0.020229978\n",
    "Balanced\tB14\tL24_E22_20_B14_D10_12\t0.01176616\t0.018031228\n",
    "Balanced\tB14\tL24_E22_20_B14_D12_14\t0.011317902\t0.017977262\n",
    "Balanced\tB14\tL24_E22_20_B14_D14_16\t0.007932813\t0.014028862\n",
    "Balanced\tB14\tL24_E22_20_B14_D16_18\t0.006903451\t0.012411846\n",
    "Balanced\tB14\tL24_E22_20_B14_D18_20\t0.007345156\t0.012912999\n",
    "Balanced\tB14\tL24_E22_20_B14_D20_22\t0.006574532\t0.011853616\n",
    "Balanced\tB16\tL24_E10_8_B16_D8_10\t0.01443889\t0.022198021\n",
    "Balanced\tB16\tL24_E10_8_B16_D10_12\t0.012854735\t0.021357154\n",
    "Balanced\tB16\tL24_E10_8_B16_D12_14\t0.010929574\t0.018578915\n",
    "Balanced\tB16\tL24_E10_8_B16_D14_16\t0.012646293\t0.018443601\n",
    "Balanced\tB16\tL24_E10_8_B16_D16_18\t0.010945445\t0.016249189\n",
    "Balanced\tB16\tL24_E10_8_B16_D18_20\t0.01253196\t0.019771604\n",
    "Balanced\tB16\tL24_E10_8_B16_D20_22\t0.010982584\t0.018833345\n",
    "Balanced\tB16\tL24_E12_10_B16_D8_10\t0.010218883\t0.017238794\n",
    "Balanced\tB16\tL24_E12_10_B16_D10_12\t0.011635716\t0.018228777\n",
    "Balanced\tB16\tL24_E12_10_B16_D12_14\t0.011159241\t0.018570641\n",
    "Balanced\tB16\tL24_E12_10_B16_D14_16\t0.011635184\t0.019652108\n",
    "Balanced\tB16\tL24_E12_10_B16_D16_18\t0.007601895\t0.013697112\n",
    "Balanced\tB16\tL24_E12_10_B16_D18_20\t0.011896968\t0.019023377\n",
    "Balanced\tB16\tL24_E12_10_B16_D20_22\t0.007902916\t0.013832669\n",
    "Balanced\tB16\tL24_E14_12_B16_D8_10\t0.012019927\t0.017690079\n",
    "Balanced\tB16\tL24_E14_12_B16_D10_12\t0.013313841\t0.019373478\n",
    "Balanced\tB16\tL24_E14_12_B16_D12_14\t0.014628788\t0.021947896\n",
    "Balanced\tB16\tL24_E14_12_B16_D14_16\t0.01148012\t0.020053944\n",
    "Balanced\tB16\tL24_E14_12_B16_D16_18\t0.011231527\t0.017585358\n",
    "Balanced\tB16\tL24_E14_12_B16_D18_20\t0.008087044\t0.013754104\n",
    "Balanced\tB16\tL24_E14_12_B16_D20_22\t0.010989663\t0.018836258\n",
    "Balanced\tB16\tL24_E16_14_B16_D8_10\t0.013403513\t0.02059768\n",
    "Balanced\tB16\tL24_E16_14_B16_D10_12\t0.007176968\t0.012844114\n",
    "Balanced\tB16\tL24_E16_14_B16_D12_14\t0.01657103\t0.024360161\n",
    "Balanced\tB16\tL24_E16_14_B16_D14_16\t0.009002742\t0.015618296\n",
    "Balanced\tB16\tL24_E16_14_B16_D16_18\t0.01029524\t0.016195424\n",
    "Balanced\tB16\tL24_E16_14_B16_D18_20\t0.007956126\t0.014988977\n",
    "Balanced\tB16\tL24_E16_14_B16_D20_22\t0.009384157\t0.014599309\n",
    "Balanced\tB16\tL24_E18_16_B16_D8_10\t0.009789838\t0.014376386\n",
    "Balanced\tB16\tL24_E18_16_B16_D10_12\t0.011615248\t0.018652843\n",
    "Balanced\tB16\tL24_E18_16_B16_D12_14\t0.00925892\t0.014856027\n",
    "Balanced\tB16\tL24_E18_16_B16_D14_16\t0.006569106\t0.011911848\n",
    "Balanced\tB16\tL24_E18_16_B16_D16_18\t0.007048017\t0.015030492\n",
    "Balanced\tB16\tL24_E18_16_B16_D18_20\t0.008414931\t0.012840476\n",
    "Balanced\tB16\tL24_E18_16_B16_D20_22\t0.007079652\t0.012801006\n",
    "Balanced\tB16\tL24_E20_18_B16_D8_10\t0.011535152\t0.018558541\n",
    "Balanced\tB16\tL24_E20_18_B16_D10_12\t0.010705016\t0.017237978\n",
    "Balanced\tB16\tL24_E20_18_B16_D12_14\t0.007287473\t0.011645617\n",
    "Balanced\tB16\tL24_E20_18_B16_D14_16\t0.007791022\t0.013920991\n",
    "Balanced\tB16\tL24_E20_18_B16_D16_18\t0.010161802\t0.015694067\n",
    "Balanced\tB16\tL24_E20_18_B16_D18_20\t0.009407548\t0.015331412\n",
    "Balanced\tB16\tL24_E20_18_B16_D20_22\t0.007467068\t0.013502462\n",
    "Balanced\tB16\tL24_E22_20_B16_D8_10\t0.012481581\t0.018508103\n",
    "Balanced\tB16\tL24_E22_20_B16_D10_12\t0.01088657\t0.016404072\n",
    "Balanced\tB16\tL24_E22_20_B16_D12_14\t0.012155175\t0.018602479\n",
    "Balanced\tB16\tL24_E22_20_B16_D14_16\t0.007059867\t0.012669311\n",
    "Balanced\tB16\tL24_E22_20_B16_D16_18\t0.009708018\t0.017470954\n",
    "Balanced\tB16\tL24_E22_20_B16_D18_20\t0.008027255\t0.012676523\n",
    "Balanced\tB16\tL24_E22_20_B16_D20_22\t0.007021849\t0.012291384\n",
    "Balanced\tB18\tL24_E10_8_B18_D10_12\t0.01695957\t0.024558404\n",
    "Balanced\tB18\tL24_E16_14_B18_D8_10\t0.015121065\t0.023229439\n",
    "Balanced\tB18\tL24_E10_8_B18_D8_10\t0.014125844\t0.021659775\n",
    "Balanced\tB18\tL24_E22_20_B18_D8_10\t0.013319398\t0.023895433\n",
    "Balanced\tB18\tL24_E18_16_B18_D10_12\t0.013304006\t0.019484282\n",
    "Balanced\tB18\tL24_E10_8_B18_D12_14\t0.012314063\t0.018517887\n",
    "Balanced\tB18\tL24_E12_10_B18_D8_10\t0.01228983\t0.019133694\n",
    "Balanced\tB18\tL24_E14_12_B18_D8_10\t0.012207462\t0.01828197\n",
    "Balanced\tB18\tL24_E16_14_B18_D10_12\t0.012191797\t0.018332638\n",
    "Balanced\tB18\tL24_E10_8_B18_D14_16\t0.012113245\t0.019373765\n",
    "Balanced\tB18\tL24_E22_20_B18_D12_14\t0.011712676\t0.019212885\n",
    "Balanced\tB18\tL24_E14_12_B18_D20_22\t0.011445946\t0.017618913\n",
    "Balanced\tB18\tL24_E12_10_B18_D14_16\t0.011347599\t0.018519077\n",
    "Balanced\tB18\tL24_E12_10_B18_D12_14\t0.011273368\t0.018799953\n",
    "Balanced\tB18\tL24_E20_18_B18_D8_10\t0.011256037\t0.017441269\n",
    "Balanced\tB18\tL24_E12_10_B18_D16_18\t0.011087871\t0.018308533\n",
    "Balanced\tB18\tL24_E16_14_B18_D16_18\t0.010889485\t0.018337818\n",
    "Balanced\tB18\tL24_E18_16_B18_D8_10\t0.010852436\t0.017056787\n",
    "Balanced\tB18\tL24_E14_12_B18_D12_14\t0.010757718\t0.017448986\n",
    "Balanced\tB18\tL24_E10_8_B18_D18_20\t0.01065963\t0.016878871\n",
    "Balanced\tB18\tL24_E20_18_B18_D12_14\t0.010095704\t0.015183505\n",
    "Balanced\tB18\tL24_E12_10_B18_D10_12\t0.009935365\t0.015215641\n",
    "Balanced\tB18\tL24_E20_18_B18_D14_16\t0.009471943\t0.013873239\n",
    "Balanced\tB18\tL24_E14_12_B18_D18_20\t0.009420007\t0.014936462\n",
    "Balanced\tB18\tL24_E20_18_B18_D20_22\t0.009338461\t0.01569205\n",
    "Balanced\tB18\tL24_E10_8_B18_D16_18\t0.009127922\t0.014893274\n",
    "Balanced\tB18\tL24_E14_12_B18_D16_18\t0.009079733\t0.013138008\n",
    "Balanced\tB18\tL24_E22_20_B18_D10_12\t0.008860467\t0.015600192\n",
    "Balanced\tB18\tL24_E20_18_B18_D16_18\t0.008754261\t0.014281114\n",
    "Balanced\tB18\tL24_E18_16_B18_D14_16\t0.008641821\t0.015084272\n",
    "Balanced\tB18\tL24_E16_14_B18_D14_16\t0.008624752\t0.014314129\n",
    "Balanced\tB18\tL24_E10_8_B18_D20_22\t0.008519571\t0.014369097\n",
    "Balanced\tB18\tL24_E18_16_B18_D12_14\t0.008169321\t0.012955836\n",
    "Balanced\tB18\tL24_E14_12_B18_D10_12\t0.008127244\t0.014743481\n",
    "Balanced\tB18\tL24_E18_16_B18_D16_18\t0.008117163\t0.014629924\n",
    "Balanced\tB18\tL24_E20_18_B18_D10_12\t0.008108931\t0.012854083\n",
    "Balanced\tB18\tL24_E16_14_B18_D18_20\t0.008108213\t0.013673033\n",
    "Balanced\tB18\tL24_E22_20_B18_D14_16\t0.008028419\t0.013705629\n",
    "Balanced\tB18\tL24_E14_12_B18_D14_16\t0.007903464\t0.01299998\n",
    "Balanced\tB18\tL24_E20_18_B18_D18_20\t0.007793906\t0.013070653\n",
    "Balanced\tB18\tL24_E22_20_B18_D16_18\t0.007581891\t0.012241531\n",
    "Balanced\tB18\tL24_E16_14_B18_D12_14\t0.007469062\t0.012449068\n",
    "Balanced\tB18\tL24_E18_16_B18_D18_20\t0.007463417\t0.012717633\n",
    "Balanced\tB18\tL24_E16_14_B18_D20_22\t0.00730257\t0.01348797\n",
    "Balanced\tB18\tL24_E22_20_B18_D18_20\t0.007228242\t0.012477516\n",
    "Balanced\tB18\tL24_E22_20_B18_D20_22\t0.006432029\t0.012578507\n",
    "Balanced\tB18\tL24_E12_10_B18_D18_20\t0.006421868\t0.012517379\n",
    "Balanced\tB18\tL24_E12_10_B18_D20_22\t0.006370554\t0.013798644\n",
    "Balanced\tB18\tL24_E18_16_B18_D20_22\t0.00622308\t0.011526386\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
