{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f34cd4de",
   "metadata": {},
   "source": [
    "## BalancedEncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "ip_address = socket.gethostbyname(hostname)\n",
    "\n",
    "# Print the SSH address\n",
    "ssh_address = f\"{hostname}@{ip_address}\"\n",
    "print(f\"SSH Address: {ssh_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55641120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable Warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ae2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Get the list of available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"Available GPUs:\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6619f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE1 = '../SB-001/SB-001_normalized_AM.csv'\n",
    "FILE2 = '../SB-001/SB-001_normalized_PM.csv'\n",
    "NO_OF_COLUMNS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942103a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tf2onnx\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import cv2\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from gretel_client.config import RunnerMode\n",
    "from gretel_client.evaluation.quality_report import QualityReport\n",
    "from gretel_client import configure_session\n",
    "from gretel_client.projects import create_or_get_unique_project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings('ignore', message=r'.*Consider either turning off auto-sharding.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # GPU Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your gretel API key ready befor running this\n",
    "import pandas as pd\n",
    "from gretel_client.config import RunnerMode\n",
    "from gretel_client.evaluation.quality_report import QualityReport\n",
    "from gretel_client import configure_session\n",
    "from gretel_client.projects import create_or_get_unique_project\n",
    "\n",
    "# Specify your Gretel API Key\n",
    "\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "configure_session(api_key=\"prompt\", cache=\"yes\", validate=True)\n",
    "run_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c878f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autoencoder_reports(encoder_dense_layers, bottle_neck, decoder_dense_layers):\n",
    "\n",
    "    print(encoder_dense_layers, bottle_neck, decoder_dense_layers)\n",
    "    # Load Data\n",
    "    df_am = pd.read_csv(FILE1)\n",
    "    df_pm = pd.read_csv(FILE2)\n",
    "    combined_df = pd.concat([df_am, df_pm])\n",
    "\n",
    "    columns_needed = ['y_am_pef', 'tempin', 'humidin', 'pm25in', 'co2in', 'tempdiffin', 'humidiffin', 'pm25diffin',\n",
    "                      'pm10', 'pm25', 'o3', 'no2', 'co', 'so2', 'temp', 'windsd', 'humid', 'varp', 'dewpt', 'airp',\n",
    "                      'seap', 'solrhr', 'solramnt', 'grdt', 'class']\n",
    "    combined_df = combined_df.filter(columns_needed)\n",
    "    df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Drop NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Minotity Split\n",
    "    class_counts = df['class'].value_counts()\n",
    "    minority_class = df[df['class'] == 0]\n",
    "    majority_class = df[df['class'] == 1]\n",
    "\n",
    "    # Removing class column from minority before augmentation\n",
    "    X = minority_class.drop('class', axis=1)\n",
    "    y = minority_class['class']\n",
    "\n",
    "    # Saving minority as X_train\n",
    "    X_train = X\n",
    "\n",
    "    # Define the Input shape\n",
    "    INPUT_SHAPE = X_train.shape[1]\n",
    "    FILE_NAME = f\"L{INPUT_SHAPE}_E{'_'.join(map(str, encoder_dense_layers))}_B{bottle_neck}_D{'_'.join(map(str, decoder_dense_layers))}\"\n",
    "    print(\"\\n\" + FILE_NAME + \"\\n\")\n",
    "    \n",
    "    def build_autoencoder(input_shape, **kwargs):\n",
    "\n",
    "        # Autoencoder model construction cod\n",
    "\n",
    "      \"\"\"\n",
    "      Build an autoencoder model with the given configuration.\n",
    "\n",
    "      Args:\n",
    "          input_shape (int): The shape of the input data.\n",
    "          **kwargs: Additional keyword arguments for configuring the autoencoder.\n",
    "\n",
    "      Keyword Args:\n",
    "          encoder_dense_layers (list): List of integers specifying the number of units for each dense layer in the encoder.\n",
    "                                      Default: []\n",
    "          bottle_neck (int): The number of units in the bottleneck layer. Default: input_shape // 2\n",
    "          decoder_dense_layers (list): List of integers specifying the number of units for each dense layer in the decoder.\n",
    "                                      Default: []\n",
    "          decoder_activation (str): The activation function for the decoder output layer. Default: 'sigmoid'\n",
    "\n",
    "      Returns:\n",
    "          tuple: A tuple containing the autoencoder, encoder, and decoder models.\n",
    "\n",
    "      Example:\n",
    "          INPUT_SHAPE = 27\n",
    "          encoder_dense_layers = [20, 18]  # Specify the number of units for each dense layer in the encoder\n",
    "          bottle_neck = 16\n",
    "          decoder_dense_layers = [18, 20]  # Specify the number of units for each dense layer in the decoder\n",
    "\n",
    "          autoencoder, encoder, decoder = build_autoencoder(INPUT_SHAPE, encoder_dense_layers=encoder_dense_layers,\n",
    "                                                            bottle_neck=bottle_neck, decoder_dense_layers=decoder_dense_layers)\n",
    "          encoder.summary()\n",
    "          decoder.summary()\n",
    "          autoencoder.summary()\n",
    "      \"\"\"\n",
    "\n",
    "      # Default parameter values\n",
    "      encoder_dense_layers = kwargs.get('encoder_dense_layers', [])\n",
    "      bottle_neck = kwargs.get('bottle_neck', input_shape // 2)\n",
    "      decoder_dense_layers = kwargs.get('decoder_dense_layers', [])\n",
    "      decoder_activation = kwargs.get('decoder_activation', 'sigmoid')\n",
    "\n",
    "      # Autoencoder Model\n",
    "      encoder_input = keras.Input(shape=(input_shape,), name=\"encoder\")\n",
    "      x = keras.layers.Flatten()(encoder_input)\n",
    "\n",
    "      # Encoder Dense Layers\n",
    "      for units in encoder_dense_layers:\n",
    "          x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
    "\n",
    "      encoder_output = keras.layers.Dense(bottle_neck, activation=\"relu\")(x)\n",
    "      encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "      # Decoder Model\n",
    "      decoder_input = keras.Input(shape=(bottle_neck,), name=\"decoder\")\n",
    "      x = decoder_input\n",
    "\n",
    "      # Decoder Dense Layers\n",
    "      for units in decoder_dense_layers:\n",
    "          x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
    "\n",
    "      decoder_output = keras.layers.Dense(input_shape, activation=decoder_activation)(x)\n",
    "      decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "      # Autoencoder Model\n",
    "      autoencoder_input = keras.Input(shape=(input_shape,), name=\"input\")\n",
    "      encoded = encoder(autoencoder_input)\n",
    "      decoded = decoder(encoded)\n",
    "      autoencoder = keras.Model(autoencoder_input, decoded, name=\"autoencoder\")\n",
    "\n",
    "      return autoencoder, encoder, decoder\n",
    "\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    with strategy.scope():\n",
    "        autoencoder, encoder, decoder = build_autoencoder(INPUT_SHAPE, encoder_dense_layers=encoder_dense_layers,\n",
    "                                                          bottle_neck=bottle_neck,\n",
    "                                                          decoder_dense_layers=decoder_dense_layers)\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        autoencoder.compile(opt, loss=\"mse\")\n",
    "\n",
    "        print(\"Training model:\", FILE_NAME)\n",
    "        history = autoencoder.fit(X_train, X_train, epochs=200, batch_size=16, validation_split=0.25, verbose=0)\n",
    "        print(\"Training Complete:\")\n",
    "    \n",
    "    # Extract the loss values\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Print the last epoch's loss values\n",
    "    last_epoch_loss = loss[-1]\n",
    "    last_epoch_val_loss = val_loss[-1]\n",
    "    print(\"Last epoch loss:\", last_epoch_loss)\n",
    "    print(\"Last epoch validation loss:\", last_epoch_val_loss)\n",
    "\n",
    "    # Saving history\n",
    "    with open(FILE_NAME + 'history.pickle', 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "    # Visualize losses *(MSE)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(FILE_NAME + 'Loss.png')\n",
    "    #plt.show()\n",
    "\n",
    "    # Generate synthetic data\n",
    "    num_samples = len(X_train)\n",
    "    input_data = np.random.normal(size=(num_samples, INPUT_SHAPE))\n",
    "    generated_data = autoencoder.predict(input_data)\n",
    "    reshaped_data = generated_data.reshape(num_samples, -1)\n",
    "    df_generated = pd.DataFrame(reshaped_data, columns=X_train.columns)\n",
    "\n",
    "    # Plot correlation matrices\n",
    "    corr_matrix1 = X_train.corr()\n",
    "    corr_matrix2 = df_generated.corr()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "    sns.heatmap(corr_matrix1, annot=True, cmap='coolwarm', ax=axes[0])\n",
    "    axes[0].set_title('Heatmap 1')\n",
    "\n",
    "    sns.heatmap(corr_matrix2, annot=True, cmap='coolwarm', ax=axes[1])\n",
    "    axes[1].set_title('Heatmap 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FILE_NAME + 'HeatMaps')\n",
    "    #plt.show()\n",
    "\n",
    "    # Calculate mean and standard deviation of original and synthetic datasets\n",
    "    common_columns = set(X_train.columns) & set(df_generated.columns)\n",
    "    results = {}\n",
    "\n",
    "    for column in common_columns:\n",
    "        mean_df1 = X_train[column].mean()\n",
    "        std_df1 = X_train[column].std()\n",
    "        mean_df2 = df_generated[column].mean()\n",
    "        std_df2 = df_generated[column].std()\n",
    "\n",
    "        results[column] = {'Mean_df1': mean_df1, 'Std_df1': std_df1,\n",
    "                           'Mean_df2': mean_df2, 'Std_df2': std_df2}\n",
    "\n",
    "    comparison_df = pd.DataFrame(results)\n",
    "    comparison_df.to_csv(FILE_NAME + 'mean_std.csv', index=True)\n",
    "\n",
    "    # Plot scatter plots\n",
    "    new_index = pd.RangeIndex(start=0, stop=57, step=1)\n",
    "    X_train = X_train.set_index(new_index)\n",
    "    common_columns = set(X_train.columns) & set(df_generated.columns)\n",
    "\n",
    "    for column in common_columns:\n",
    "        plt.scatter(X_train.index, X_train[column], color='red', label='X_train')\n",
    "        plt.scatter(df_generated.index, df_generated[column], color='blue', label='df_generated')\n",
    "\n",
    "        plt.title(f\"Scatter Plot: {column}\")\n",
    "        plt.xlabel(\"Index\")\n",
    "        plt.ylabel(column)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.savefig(FILE_NAME + \"_\" + column)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    # Add back the class label\n",
    "    X_train['class'] = 0.0\n",
    "    df_generated['class'] = 0.0\n",
    "    X_train.to_csv(FILE_NAME + 'Original_minority_data.csv', index=False)\n",
    "    df_generated.to_csv(FILE_NAME + 'Synthetic_minority_data.csv', index=False)\n",
    "\n",
    "    # Generate quality report and display it\n",
    "    real_data = FILE_NAME + 'Original_minority_data.csv'\n",
    "    synth_data = FILE_NAME + 'Synthetic_minority_data.csv'\n",
    "\n",
    "    report = QualityReport(data_source=synth_data, ref_data=real_data)\n",
    "    report.run()\n",
    "\n",
    "    print(report.peek())\n",
    "    run_summary.append([FILE_NAME, report.peek()['raw_score'], report.peek()['grade']])\n",
    "    print(\"Reports Saved\")\n",
    "    #IPython.display.HTML(report.as_html, metadata=dict(isolated=True))\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def runner(encoder_dense_layers, bottle_neck, decoder_dense_layers):\n",
    "  #encoder_dense_layers = [10, 8]\n",
    "  #bottle_neck = 5\n",
    "  #decoder_dense_layers = [8, 10]\n",
    "  #FILE_NAME = f\"24_{'_'.join(map(str, encoder_dense_layers))}_{bottle_neck}_\"\n",
    "  FILE_NAME = f\"L{NO_OF_COLUMNS}_E{'_'.join(map(str, encoder_dense_layers))}_B{bottle_neck}_D{'_'.join(map(str, decoder_dense_layers))}-\"   \n",
    "  report = generate_autoencoder_reports(encoder_dense_layers, bottle_neck, decoder_dense_layers)\n",
    "  #print(type(report))\n",
    "  # Save the report object to a file\n",
    "  with open(FILE_NAME + 'quality_report.pickle', 'wb') as file:\n",
    "      pickle.dump(report, file)\n",
    "\n",
    "  #IPython.display.HTML(report.as_html, metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f54d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes nothin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dense_layers_trial = [[10, 8], [12, 10], [14, 12], [16, 14], [18, 16], [20, 18] ,[22,20]]\n",
    "decoder_dense_layers_trial = [[8, 10], [10, 12], [12, 14], [14, 16], [16, 18], [18, 20], [20,22]]\n",
    "bottle_neck_trial = [8, 10, 12, 14, 16, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748637dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = len(bottle_neck_trial) * len(encoder_dense_layers_trial) * len(decoder_dense_layers_trial)\n",
    "print(\"Total Model in Pipeline:\",total_iterations)\n",
    "\n",
    "#print total models\n",
    "with tqdm(total=total_iterations, desc=\"Overall Progress\") as pbar:\n",
    "    for bn in bottle_neck_trial:\n",
    "        for enc_layers in encoder_dense_layers_trial:\n",
    "            for dec_layers in decoder_dense_layers_trial:\n",
    "                pbar.set_postfix({\"Encoder Dense Layers\": enc_layers, \"Decoder Dense Layers\": dec_layers, \"Bottle Neck\": bn})\n",
    "                print(enc_layers, bn, dec_layers)\n",
    "                pbar.update(1)\n",
    "\n",
    "               \n",
    "\n",
    "\n",
    "# encoder_dense_layers_trial = [[10, 8], [12, 10], [14, 12], [16, 14], [18, 16], [20, 18] ,[22,20]]\n",
    "# decoder_dense_layers_trial = [[8, 10], [10, 12], [12, 14], [14, 16], [16, 18], [18, 20], [20,22]]\n",
    "# bottle_neck_trial = [8, 10, 12, 14, 16, 18]\n",
    "\n",
    "# for bn in bottle_neck_trial:\n",
    "#     for enc_layers, dec_layers in zip(encoder_dense_layers_trial, decoder_dense_layers_trial):\n",
    "#         print(f\"Encoder Dense Layers: {enc_layers}, Decoder Dense Layers: {dec_layers}, Bottle Neck: {bn}\")\n",
    "#         runner(enc_layers, bn, dec_layers)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Overall Progress\") as pbar:\n",
    "    for bn in bottle_neck_trial:\n",
    "        for enc_layers in encoder_dense_layers_trial:\n",
    "            for dec_layers in decoder_dense_layers_trial:\n",
    "                pbar.set_postfix({\"Encoder Dense Layers\": enc_layers, \"Decoder Dense Layers\": dec_layers, \"Bottle Neck\": bn})\n",
    "                runner(enc_layers, bn, dec_layers)\n",
    "                pbar.update(1) \n",
    "                \n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time                \n",
    "total_time_minutes = total_time / 60\n",
    "print(f\"Total time: {total_time_minutes} minutes\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23144953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save run_summary as a file\n",
    "filename = 'run_summary.csv'\n",
    "\n",
    "with open(filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(run_summary)\n",
    "\n",
    "print(f\"Run summary has saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_summary.sort(key=lambda x: x[1], reverse=True)  # Sort by the middle value in descending order\n",
    "\n",
    "top_10 = run_summary[:10]  # Get the top 10 elements\n",
    "\n",
    "for item in top_10:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722038a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
